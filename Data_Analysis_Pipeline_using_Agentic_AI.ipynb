{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install -q langgraph  pysqlite3-binary openai matplotlib\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\""
      ],
      "metadata": {
        "id": "hrw1vlpucOU9"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import sqlite3\n",
        "from typing import Optional, TypedDict, Dict, Any\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "from openai import OpenAI\n",
        "from langgraph.graph import StateGraph, END"
      ],
      "metadata": {
        "id": "KREf83pWLJ5O"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------------------------------\n",
        "# Upload CSV & Prep data\n",
        "# ----------------------------------------------------\n",
        "try:\n",
        "  uploaded = files.upload()\n",
        "  csv_path = list(uploaded.keys())[0]\n",
        "except Exception:\n",
        "   print('Please upload your data file.')\n",
        "   try:\n",
        "    uploaded = files.upload()\n",
        "    csv_path = list(uploaded.keys())[0]\n",
        "   except Exception:\n",
        "    raise FileNotFoundError('No files uploaded after second attempt.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "4jNSgxp-ORGY",
        "outputId": "db45fc3c-b919-4850-94e4-8699ea824c80"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b5d4d73c-9152-4f3d-867e-0f8c50f1c89c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b5d4d73c-9152-4f3d-867e-0f8c50f1c89c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving synthetic_bank_customer_data(in).csv to synthetic_bank_customer_data(in) (3).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------------------------------\n",
        "# Load Data and Perform Basic Transformations\n",
        "# ----------------------------------------------------\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Clean & transform data\n",
        "for col in ['Name', 'Surname', 'Gender', 'Region', 'Job Classification']:\n",
        "  if col in df.columns:\n",
        "    df[col] = df[col].astype(str).str.strip()\n",
        "\n",
        "\n",
        "df['Date Joined'] = pd.to_datetime(df['Date Joined'], format = '%d.%b.%y')\n",
        "df['Year Month'] = df['Date Joined'].dt.to_period('M').astype(str) # YYYY-MM\n",
        "\n",
        "\n",
        "for c, t in [('Customer ID', 'int64'), ('Age', 'int64'), ('Balance', 'float64')]:\n",
        "  if c in df.columns:\n",
        "    df[c] = df[c].astype(t)\n",
        "\n",
        "df['Age Group'] = pd.cut(df['Age'], bins = [0, 25, 35, 45, 55, 60, 100],\n",
        "                         labels = ['18-25', '26-35', '36-45', '46-55', '56-65', '65+'],\n",
        "                         right = True)\n",
        "def check_yoy_availability(_df: pd.DataFrame) -> bool:\n",
        "  if 'Date Joined' not in _df.columns:\n",
        "    return False\n",
        "  years = pd.to_datetime(_df['Date Joined']).dt.year.dropna().unique()\n",
        "  return len(years) > 1"
      ],
      "metadata": {
        "id": "E9y2Jt3LPBk4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df.head(2)\n"
      ],
      "metadata": {
        "id": "mIj7MSpG3BiC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------------------------------\n",
        "# Save CSV to SQLite DB\n",
        "# ----------------------------------------------------\n",
        "# Saving to SQLite\n",
        "db_path = 'bank_customer.db'\n",
        "with sqlite3.connect(db_path) as conn:\n",
        "  df.to_sql('customers', conn, if_exists = 'replace', index = False)\n",
        "\n",
        "# SQL Helper\n",
        "def run_sql_query(query: str, db_path: Optional[str] = db_path) -> pd.DataFrame:\n",
        "  with sqlite3.connect(db_path) as conn:\n",
        "    return pd.read_sql_query(query, conn)"
      ],
      "metadata": {
        "id": "UvAAd2q543jo"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------------------------------\n",
        "# Graph State & Helpers\n",
        "# ----------------------------------------------------\n",
        "class QAState(TypedDict, total = False):\n",
        "  question: str\n",
        "  resolved_question: Optional[str]\n",
        "  assumption: Optional[str]\n",
        "  schema_hint: Optional[str]\n",
        "  sql: Optional[str]\n",
        "  error: Optional[str]\n",
        "  intent: Optional[str]\n",
        "  result: Optional[pd.DataFrame]\n",
        "  df_for_plot: Optional[pd.DataFrame]\n",
        "  viz_note: Optional[str]\n",
        "  answer: Optional[str]\n",
        "  log: Dict[str, Any]"
      ],
      "metadata": {
        "id": "zD9xrToEkA8-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------------------------------\n",
        "# Setting up OpenAI Client, Configs & Intent\n",
        "# ----------------------------------------------------\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "ALLOWED_COLS = []\n",
        "REQUIRED_BRACKETS = {\"Customer ID\", \"Job Classification\", \"Date Joined\", \"Year Month\", \"Age Group\"}\n",
        "GROWTH_MOM_KEYS = {\"mom\", \"month over month\", \"month-on-month\",\"m/m\"}\n",
        "GROWTH_YOY_KEYS = {\"yoy\", \"year over year\", \"year-over-year\", \"y/y\"}\n",
        "PREDICT_KEYS = {\"predict\", \"forecast\", \"trend\", \"future\", \"project\", \"projection\"}\n",
        "\n",
        "# Detect Intention of Question\n",
        "def detect_intent(ques: str) -> str:\n",
        "  ql = (ques or \"\").lower()\n",
        "  if any(w in ql for w in PREDICT_KEYS):\n",
        "    return 'predict'\n",
        "  elif any(w in ql for w in GROWTH_YOY_KEYS):\n",
        "    return 'growth_yoy'\n",
        "  elif any(w in ql for w in GROWTH_MOM_KEYS) or 'growth' in ql:\n",
        "    return 'growth_mom'\n",
        "  else:\n",
        "    return 'generic'\n",
        "\n"
      ],
      "metadata": {
        "id": "0M8wPm0flE-e"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------------------------------\n",
        "# Nodes\n",
        "# ----------------------------------------------------\n",
        "\n",
        "# 1. Schema auto-discovery for validating schema_hint from DB\n",
        "def discover_schema(state: QAState) -> QAState:\n",
        "  pragma = run_sql_query(\"PRAGMA table_info(customers);\")\n",
        "  cols = pragma['name'].tolist()\n",
        "  global ALLOWED_COLS\n",
        "  ALLOWED_COLS = cols\n",
        "  # Building Schema hint\n",
        "  lines = [\"TABLE customers columns (use EXACT names, bracket spaces):\"]\n",
        "  for c in cols:\n",
        "    if any(ch in c for ch in [\" \", \"-\", \"_\"]):\n",
        "      lines.append(f\"- [{c}] (type inferred\")\n",
        "    else:\n",
        "      lines.append(f\"- {c} (type inferred\")\n",
        "  state['schema_hint'] = \"\\n\".join(lines)\n",
        "  return state\n",
        "\n",
        "\n",
        "# 2. Clarifying on growth questions\n",
        "def clarify(state: QAState) -> QAState:\n",
        "  q = state['question']\n",
        "  intent = detect_intent(q)\n",
        "  # -- Check YoY availability\n",
        "  years = []\n",
        "  if 'Date Joined' in df.columns:\n",
        "    years = sorted(pd.to_datetime(df['Date Joined']).dt.year.dropna().unique())\n",
        "  if intent == 'growth_yoy' and len(years)<= 1:\n",
        "    state['intent'] = 'growth_yoy_unavailable'\n",
        "    state['answer'] = (\n",
        "        f\"Year-over-Year growth unavailable.Only\"\n",
        "        f\"{', '.join(map(str, years)) or 'no'} year(s) of data found.\"\n",
        "    )\n",
        "    return state\n",
        "  # -- Assuming MoM only if question without clear timeframe.\n",
        "  need_assumption = (intent == \"growth_mom\" and not any(k in q.lower() for k in ['yoy', 'year', 'month', '201', '202']))\n",
        "  state['assumption'] = \"Assumed month-over-month over the available period.\" if need_assumption else None\n",
        "  state['resolved_question'] = q + \" Assume month-over-month over the available period.\" if need_assumption else q\n",
        "  state['intent'] = intent\n",
        "  return state\n",
        "\n",
        "\n",
        "# 3. LLM to SQL, using discovered schema.\n",
        "def llm_to_sql(state: QAState) -> QAState:\n",
        "  if state.get('intent') == 'growth_yoy_unavailable' and state.get('answer'):\n",
        "    return state\n",
        "  intent = state.get('intent', 'generic')\n",
        "  schema_hint = state.get('schema_hint','')\n",
        "  question = state.get('resolved_question') or state['question']\n",
        "  if intent == 'growth_mom':\n",
        "    user_prompt = (\n",
        "        \"Return ONLY executable SQLite SQL. No prose/markdown. Use table `customers`.\\n\"\n",
        "        \"Use exact column names. Bracket spaces like [Customer ID].\\n\"\n",
        "        \"Compute month-over-month growth using counts of [Customer ID].\\n\"\n",
        "        \"If comparing months, derive next month with date([Year Month] || '-01', '+1 month').\\n\\n\"\n",
        "        f\"Question: {question}\\n\\n{schema_hint}\"\n",
        "    )\n",
        "  if intent == 'growth_yoy':\n",
        "    user_prompt = (\n",
        "        \"Return ONLY executable SQLite SQL. No prose/markdown. Use table `customers`.\\n\"\n",
        "        \"Use exact column names. Bracket spaces like [Customer ID].\\n\"\n",
        "        \"Compute year-over-year growth using counts of [Customer ID].\\n\"\n",
        "        \"Compare same month vs previous year via date([Year Month] || '-01', '-1 year').\\n\\n\"\n",
        "        f\"Question: {question}\\n\\n{schema_hint}\"\n",
        "    )\n",
        "  else:\n",
        "    user_prompt = (\n",
        "        \"Return ONLY executable SQLite SQL. No prose/markdown. Use table `customers`.\\n\"\n",
        "        \"Use exact column names. Bracket spaces like [Customer ID].\\n\"\n",
        "        \"Prefer CTEs for clarity.\\n\\n\"\n",
        "        f\"Question: {question}\\n\\n{schema_hint}\"\n",
        "    )\n",
        "\n",
        "  response = client.chat.completions.create(\n",
        "      model = 'gpt-4o',\n",
        "      messages = [\n",
        "          {'role': 'system', 'content': \"Return ONLY SQL for SQLite over the `customers` table.\"},\n",
        "           {'role': 'user', 'content': user_prompt}\n",
        "                  ],\n",
        "      temperature = 0\n",
        "  )\n",
        "  sql_query = response.choices[0].message.content.strip()\n",
        "  # Remove markdown from sql\n",
        "  if sql_query.startswith(\"```sql\"):\n",
        "      sql_query = sql_query[6:]\n",
        "  if sql_query.endswith(\"```\"):\n",
        "      sql_query = sql_query[:-3]\n",
        "  state['sql'] = sql_query.strip()\n",
        "  return state\n",
        "\n",
        "# 4. SQL validators and repair\n",
        "def validate_sql(state: QAState) -> QAState:\n",
        "  sql_text = (state.get('sql') or '')\n",
        "  sql_lower = sql_text.lower().strip()\n",
        "  # reject muilti statement SQL\n",
        "  if sql_lower.count(';') > 1:\n",
        "    state['error'] = \"Multiple SQL statements detected.\"\n",
        "    return state\n",
        "  # prevent table update statements\n",
        "  if any(w in sql_lower for w in ['drop', 'delete', 'update', 'insert','alter', 'pragma', 'attach', 'detach']):\n",
        "    state['error'] = \"Unsafe SQL operation detected.\"\n",
        "    return state\n",
        "  # enfore brackets for spaced columns\n",
        "  for col in ALLOWED_COLS:\n",
        "    if ' ' in col:\n",
        "      p = col.lower().replace(' ','')\n",
        "      if p in sql_lower and f\"[{col.lower()}]\" not in sql_lower:\n",
        "        state['error'] = f\"Column requires brackets: [{col}]\"\n",
        "        return state\n",
        "  # limit rows for data view requests\n",
        "  if 'select' in sql_lower and ' limit' not in sql_lower:\n",
        "    state['sql'] = state['sql'].rstrip(';') + ' LIMIT 20'\n",
        "  state['error'] = None\n",
        "  return state\n",
        "\n",
        "def repair_sql(state: QAState) -> QAState:\n",
        "  if not state.get('error'):\n",
        "    return state\n",
        "  hint = state['error']\n",
        "  schema_hint = state.get('schema_hint', '')\n",
        "  orig = state.get('sql', '')\n",
        "  resp = client.chat.completions.create(\n",
        "      model = 'gpt-4o',\n",
        "      messages = [\n",
        "          {'role': 'system', 'content': \"Return ONLY SQL for SQLite over the `customers` table.\"},\n",
        "          {'role': 'user', 'content': f\"Fix this SQL issue: {hint}. Use exact column names and brackets.\\n\\nOriginal SQL: \\n{orig}\\n\\n{schema_hint}\"}\n",
        "      ],\n",
        "      temperature = 0\n",
        "  )\n",
        "  sql = resp.choices[0].message.content.strip()\n",
        "  if sql.startswith(\"```sql\"):\n",
        "      sql = sql[6:]\n",
        "  if sql.endswith(\"```\"):\n",
        "      sql = sql[:-3]\n",
        "  state['sql'] = sql.strip()\n",
        "  return state\n",
        "\n",
        "# 5. Execute SQL with observability\n",
        "def execute_sql(state : QAState) -> QAState:\n",
        "  # for no runs\n",
        "  if not state.get('sql'):\n",
        "    state['result'] = pd.DataFrame()\n",
        "    state['log'] = {'question': state.get('question'), 'rows': 0, 'cols': 0, 'duration_sec':0}\n",
        "    return state\n",
        "  # query log info\n",
        "  t0 = time.time()\n",
        "  query = state.get('sql','')\n",
        "  df_result = run_sql_query(query) if query else pd.DataFrame()\n",
        "  duration_time = time.time() - t0\n",
        "  state['result'] = df_result\n",
        "  state['sql'] = query\n",
        "  state['log'] = {\n",
        "      'question': state.get('question'),\n",
        "      'rows': int(df_result.shape[0]) if isinstance(df_result, pd.DataFrame) else 0,\n",
        "      'cols': int(df_result.shape[1]) if isinstance(df_result, pd.DataFrame) else 0,\n",
        "      'duration_sec': round(duration_time, 4)}\n",
        "  return state\n",
        "\n",
        "# 6. Visualize output (only if asked)\n",
        "def visualize(state: QAState) -> QAState:\n",
        "  q = (state.get('question') or '').lower()\n",
        "  needs_viz = any(w in q for w in ['chart', 'plot', 'graph', 'show trend', 'visualize', 'line chart', 'bar chart', 'visualise'])\n",
        "  df_res = state.get('result')\n",
        "  # no viz if not requested or result empty\n",
        "  if not needs_viz or not isinstance(df_res, pd.DataFrame) or df_res.empty:\n",
        "    return state\n",
        "  num_cols = df_res.select_dtypes(include=[np.number]).columns.tolist()\n",
        "  date_cols = df_res.select_dtypes(include=[\"datetime64[ns]\", \"datetime64[ns, UTC]\"]).columns.tolist()\n",
        "  cat_cols = [c for c in df_res.columns if c not in (num_cols + date_cols)]\n",
        "\n",
        "  try:\n",
        "    if date_cols and num_cols:\n",
        "      # line chart\n",
        "      x, y = date_cols[0], num_cols[0]\n",
        "      df_plot = df_res.sort_values(x)\n",
        "      plt.figure()\n",
        "      plt.plot(df_plot[x], df_plot[y])\n",
        "      plt.title(f\"{y} over time\")\n",
        "      plt.xlabel(x)\n",
        "      plt.ylabel(y)\n",
        "      plt.xticks(rotation = 45)\n",
        "      plt.tight_layout()\n",
        "      plt.show()\n",
        "      state['viz note'] = f\"Line chart of {y} by {x} displayed.\"\n",
        "      state['df_for_plot'] = df_plot\n",
        "    elif cat_cols and num_cols:\n",
        "      # bar chart\n",
        "      x, y = cat_cols[0], num_cols[0]\n",
        "      df_plot = df_res.groupby(x, as_index = False)[y].sum()\n",
        "      plt.figure()\n",
        "      plt.bar(df_plot[x], df_plot[y])\n",
        "      plt.title(f\"{y} by {x}\")\n",
        "      plt.xlabel(x)\n",
        "      plt.ylabel(y)\n",
        "      plt.xticks(rotation = 45)\n",
        "      plt.tight_layout()\n",
        "      plt.show()\n",
        "      state['viz note'] = f\"Bar chart of {y} by {x} displayed.\"\n",
        "      state['df_for_plot'] = df_plot\n",
        "  except Exception:\n",
        "    pass\n",
        "  return state\n"
      ],
      "metadata": {
        "id": "FbEAShORlqan"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Explainable (Readable) Answer Summaries\n",
        "def explain(state: QAState) -> QAState:\n",
        "  df_result = state.get('result')\n",
        "  query = state.get('sql','')\n",
        "  question = (state.get('question') or \"\").lower().strip()\n",
        "  assumption = state.get('assumption')\n",
        "  log = state.get('log', {})\n",
        "  # if there was already a msg for a no output query, return it\n",
        "  if state.get('answer') and not state.get('sql'):\n",
        "    return state\n",
        "  if not isinstance(df_result, pd.DataFrame) or df_result.empty:\n",
        "    state['answer'] = ((f\"Assumption: {assumption}\\n\\n\" if assumption else \"\")+\n",
        "                       \"No rows matched your question.\\n\\n\" +\n",
        "                       f\"SQL executed:\\n{query}\\n\\n\" +\n",
        "                       f\"Observability and rows: 0, duration: {log.get('duration_sec','?')}s\"\n",
        "                       )\n",
        "    return state\n",
        "\n",
        "  # Formatting large numbers with commas and floats with 2 decimal points.\n",
        "  def fmt_num(x):\n",
        "    if pd.isna(x): return \"NA\"\n",
        "    try:\n",
        "      xf = float(x)\n",
        "      return f\"{int(xf):,}\"if xf.is_integer() else f\"{float(xf):,.2f}\"\n",
        "    except Exception:\n",
        "      return str(x)\n",
        "  # Date, Numeric and Categorical variables\n",
        "  num_cols = df_result.select_dtypes(include=[np.number]).columns.tolist()\n",
        "  date_cols = df_result.select_dtypes(include=[\"datetime64[ns]\", \"datetime64[ns, UTC]\"]).columns.tolist()\n",
        "  cat_cols = [c for c in df_result.columns if c not in (num_cols + date_cols)]\n",
        "  # Sorting result if asked\n",
        "  sort_desc_words = {'largest', 'highest', 'biggest', 'most', 'top', 'max', 'maximum', \"latest\", \"newest\"}\n",
        "  sort_asc_words = {'smallest', 'lowest', 'least', 'bottom', 'min', 'minimum', \"earliest\", \"oldest\"}\n",
        "  metric = num_cols[0] if num_cols else None\n",
        "  if metric:\n",
        "    if any(word in question for word in sort_desc_words):\n",
        "      df_result = df_result.sort_values(by = metric, ascending = False)\n",
        "    elif any(word in question for word in sort_asc_words):\n",
        "      df_result = df_result.sort_values(by = metric, ascending = True)\n",
        "\n",
        "  # Summaries\n",
        "  # Case A: Direct single value answers\n",
        "  if df_result.shape == (1,1):\n",
        "    val = df_result.iat[0, 0]\n",
        "    summary = (f\"There are {fmt_num(val)}.\" if any(k in question for k in ['how', 'many', 'count']) else f\"The result is {fmt_num(val)}.\")\n",
        "  # Case B: 1 row, many columns -> key: value summary\n",
        "  elif df_result.shape[0] == 1 and df_result.shape[1] > 1:\n",
        "    pairs = [f\"{col}: {fmt_num(df_result.iloc[0][col])}\" if col in num_cols\n",
        "             else f\"{col}: {df_result.iloc[0][col]}\"\n",
        "             for col in df_result.columns]\n",
        "    summary = \"The result row is: \" + \", \".join(pairs)\n",
        "  # Case C: 2 columns -> 1 numeric, 1 categorical\n",
        "  elif df_result.shape[1] == 2 and len(num_cols) == 1 and len(cat_cols) == 1:\n",
        "    group_col_name, metric_col_name = cat_cols[0], num_cols[0]\n",
        "    lead = \"On average, \" if any(word in metric_col_name.lower() for word in [\"avg\", \"average\", \"mean\"]) else \"\"\n",
        "    pairs = [f\"{g} have {fmt_num(v)}\" for g, v in zip(df_result[group_col_name].astype(str), df_result[metric_col_name])]\n",
        "    summary = lead + \", \".join(pairs) +\".\"\n",
        "  # Case D: Date wise summary\n",
        "  elif len(date_cols) >= 1 and df_result.shape[1] <= 3:\n",
        "    parts = []\n",
        "    for dcol in date_cols:\n",
        "      try:\n",
        "        dmin = pd.to_datetime(df_result[dcol].min())\n",
        "        dmax = pd.to_datetime(df_result[dcol].max())\n",
        "        parts.append(f\"{dcol} between {dmin} and {dmax}\")\n",
        "      except Exception:\n",
        "        parts.append(f\"{dcol} (date column)\")\n",
        "    summary = \"; \".join(parts) +\".\"\n",
        "  # Case E: 3 colums -> 2 categorical, 1 numeric\n",
        "  elif len(cat_cols) >= 1 and len(num_cols) >= 1:\n",
        "    cats, mcol = cat_cols[:2], num_cols[0]\n",
        "    items = []\n",
        "    for _, row in df_result.head(5).iterrows():\n",
        "      items.append(f\"{' & '.join(f'{c}={row[c]}' for c in cats)}: {fmt_num(row[mcol])}\")\n",
        "    prefix = 'Top ' if any(word in question for word in sort_desc_words) else \"Lowest \" if any(word in question for word in sort_asc_words) else \"Sample\"\n",
        "    summary = f\"{prefix}{min(5, len(df_result))} by {mcol}: \" + \", \".join(items) + \".\"\n",
        "  else:\n",
        "    r, c = df_result.shape\n",
        "    answer_text = f\"The query returned {r} row(s) and {c} column(s).\"\n",
        "\n",
        "  preview = df_result.head().to_string(index = False)\n",
        "  note = (f\"\\n\\nAssumption: {assumption}\" if assumption else \"\")\n",
        "  viz = (f\"\\n\\n{state.get('viz_note')}\" if state.get('viz_note') else \"\")\n",
        "  obs = f\"\\n\\nObservability and rows: {log.get('rows','?')}, cols: {log.get('cols','?')}, duration: {log.get('duration_sec','?')}s\"\n",
        "  state['df_result'] = df_result\n",
        "  state['answer'] = (\n",
        "      f\"{summary}{note}{viz}\\n\\n\"\n",
        "      f\"SQL executed:\\n {query}\\n\\n\"\n",
        "      f\"\\nPreview of result(s):\\n{preview}{obs}\")\n",
        "\n",
        "  return state\n",
        "\n"
      ],
      "metadata": {
        "id": "CdjjQP3PpIFa"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------------------------------\n",
        "# Graph Wires\n",
        "# ----------------------------------------------------\n",
        "\n",
        "# Nodes (ids, functions)\n",
        "workflow = StateGraph(QAState)\n",
        "workflow.add_node('discover_schema', discover_schema)\n",
        "workflow.add_node('clarify', clarify)\n",
        "workflow.add_node(\"generate_sql\", llm_to_sql)\n",
        "workflow.add_node(\"validate\", validate_sql)\n",
        "workflow.add_node(\"repair\", repair_sql)\n",
        "workflow.add_node(\"execute\", execute_sql)\n",
        "workflow.add_node(\"visualize\", visualize)\n",
        "workflow.add_node(\"explain\", explain)\n",
        "\n",
        "# Entry point\n",
        "workflow.set_entry_point(\"discover_schema\")\n",
        "\n",
        "# Edges\n",
        "workflow.add_edge(\"discover_schema\", \"clarify\")\n",
        "workflow.add_edge(\"clarify\", \"generate_sql\")\n",
        "workflow.add_edge(\"generate_sql\", \"validate\")\n",
        "\n",
        "def needs_repair(state: QAState) -> str:\n",
        "  return \"repair\" if state.get('error') else \"execute\"\n",
        "workflow.add_conditional_edges(\"validate\", needs_repair, {\"repair\": \"repair\", \"execute\": \"execute\"})\n",
        "\n",
        "workflow.add_edge(\"repair\", \"execute\")\n",
        "workflow.add_edge(\"execute\", \"visualize\")\n",
        "workflow.add_edge(\"visualize\", \"explain\")\n",
        "workflow.add_edge(\"explain\", END)\n",
        "\n",
        "app = workflow.compile()"
      ],
      "metadata": {
        "id": "gBtM_9OviUTF"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display\n",
        "# ----------------------------------------------------\n",
        "# Ask\n",
        "# ----------------------------------------------------\n",
        "\n",
        "# Question Function:\n",
        "def ask(question: str, mode: str = 'text'):\n",
        "  out = app.invoke(QAState(question = question))\n",
        "  if mode == 'table':\n",
        "    return out.get('result')\n",
        "  return out.get('answer','')\n",
        "\n",
        "user_question = input(\"Ask a question: \")\n",
        "mode_choice = input(\"Select mode (text/table)?: \").strip().lower() or 'text'\n",
        "print(\"\\n Running Analysis...\\n\")\n",
        "result = ask(user_question, mode = mode_choice)\n",
        "\n",
        "if mode_choice == 'table':\n",
        "  display(result)\n",
        "else:\n",
        "  print(result)"
      ],
      "metadata": {
        "id": "rPI9xU4geBVi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "422fd23a-1fa3-47e9-e41e-5e020eede02f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ask a question: Which regions have the highest concentration of specific job classifications?\n",
            "Select mode (text/table)?: text\n",
            "\n",
            " Running Analysis...\n",
            "\n",
            "Top 4 by JobCount: Region=England & Job Classification=White Collar: 1,501, Region=Scotland & Job Classification=Blue Collar: 544, Region=Wales & Job Classification=White Collar: 305, Region=Northern Ireland & Job Classification=Other: 105.\n",
            "\n",
            "SQL executed:\n",
            " WITH JobCounts AS (\n",
            "    SELECT \n",
            "        [Region], \n",
            "        [Job Classification], \n",
            "        COUNT([Customer ID]) AS JobCount\n",
            "    FROM \n",
            "        customers\n",
            "    GROUP BY \n",
            "        [Region], \n",
            "        [Job Classification]\n",
            "),\n",
            "MaxJobCounts AS (\n",
            "    SELECT \n",
            "        [Region], \n",
            "        MAX(JobCount) AS MaxJobCount\n",
            "    FROM \n",
            "        JobCounts\n",
            "    GROUP BY \n",
            "        [Region]\n",
            ")\n",
            "SELECT \n",
            "    jc.[Region], \n",
            "    jc.[Job Classification], \n",
            "    jc.JobCount\n",
            "FROM \n",
            "    JobCounts jc\n",
            "JOIN \n",
            "    MaxJobCounts mjc\n",
            "ON \n",
            "    jc.[Region] = mjc.[Region] AND \n",
            "    jc.JobCount = mjc.MaxJobCount\n",
            "ORDER BY \n",
            "    jc.[Region], \n",
            "    jc.[Job Classification] LIMIT 20\n",
            "\n",
            "\n",
            "Preview of result(s):\n",
            "          Region Job Classification  JobCount\n",
            "         England       White Collar      1501\n",
            "        Scotland        Blue Collar       544\n",
            "           Wales       White Collar       305\n",
            "Northern Ireland              Other       105\n",
            "\n",
            "Observability and rows: 4, cols: 3, duration: 0.0051s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bM5GNvbvigaR"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}